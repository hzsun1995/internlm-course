# 课程笔记 & 作业
## 课程笔记：

### 1.书生·浦语LLM的全面开源解决方案
InternLM
这是一个开源的轻量级训练框架，它的设计简洁，减少对复杂依赖的需求。InternLM-7B和InternLM-20B是两个主要模型，适用于不同规模的需求。

### 2.Lagent
Lagent是一个轻量级且开源的智能体框架，它可以最大化InternLM模型的性能，简化了智能体的开发和部署过程。

### 3.浦语·灵笔
这是以书生·浦语LLM为基础开发的视觉和语言联合大模型。它具有出色的图文理解与创作能力，可以处理和生成丰富的视觉语言内容。
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/32b39cc4-4e53-43cb-af5c-a79c0c1e243f)


### 4.InternLM-7B智能对话演示
在单个GPU上进行微调操作。
在1024个GPU上进行训练，达到了接近90%的高效加速。
包括一个具有70亿参数的基础模型和一个专门为特定场景优化的对话模型。
采用了数万亿高质量token进行训练，构建了强大的知识库。
支持8k token的上下文长度，能处理更长的输入序列，增强了推理能力。
Lagent智能体框架使用演示
轻量级且易于开源的智能体框架。
可以快速地将大型语言模型（LLM）转换成多种类型的智能体。
浦语·灵笔的图文理解与创作演示
创建具有个性化风格的图文文章。
向模型中注入大量的多模态数据，提供了强大的图文理解和对话交互能力。

## 基础作业：
#### 1.使用 InternLM-Chat-7B 模型生成 300 字的小故事（需截图）。
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/e317b38d-c62a-460a-8087-e03e2686b68a)
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/ea04761c-76f2-4a62-8d32-c634fbcb9201)

#### 2.熟悉 hugging face 下载功能，使用 huggingface_hub python 包，下载 InternLM-20B 的 config.json 文件到本地（需截图下载过程）。
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/79da054a-7097-4fa5-8f40-99f4fd13e443)
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/0c9582f3-f04a-4e0e-9f8f-dca15c6a889b)

## 进阶作业（可选做）
#### 1.完成浦语·灵笔的图文理解及创作部署（需截图）
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/53c2cb6f-d8fc-42b5-bd56-3fae34ceb6b5)
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/3ac327d6-d2e8-43f0-8586-5e337200d9ef)
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/642643e4-183d-4606-b3ad-f9a9764375c5)

#### 2.完成 Lagent 工具调用 Demo 创作部署（需截图）
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/4a450b5f-1972-4dcb-a263-a0603f50cddc)
![image](https://github.com/hzsun1995/internlm-course/assets/136775620/8c693c9c-ab5a-405b-929d-47591fe34ada)
